{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COOKIES_BUTTON = \"onetrust-accept-btn-handler\"\n",
    "CLASS_ITEM_SALE = \"new-item-box__overlay\"\n",
    "KEY_WORD_LOCATION = \"Sverige\"\n",
    "DATA_TESTID_LOCATION_PARENT = \"item-details-location\"\n",
    "CLASS_LOCATION_VALUE = \"details-list__item-value\"\n",
    "CLASS_NEXT_PAGE = \"web_ui__Pagination__next\"\n",
    "DIRECTORY_OUTPUT = \"output\"\n",
    "FILENAME_OUTPUT_LOCATION = \"location.json\"\n",
    "FILENAME_CONFIG = \"config.txt\"\n",
    "\n",
    "PATH_OUTPUT_LOCATION = os.path.join(DIRECTORY_OUTPUT, FILENAME_OUTPUT_LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Dans cette partie, on va accéder au site de Vinted. Si l'utilisateur a déjà effectué une recherche auparavant, nous souhaitons charger les filtres qu'il avait précédemment sélectionnés. Ces filtres sont stockés dans l'URL de la recherche précédente. S'il n'avait pas effectué de recherche, l'url de vinted par défaut est utilisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_vinted = \"https://www.vinted.se/\"\n",
    "\n",
    "if os.path.isfile(FILENAME_CONFIG):\n",
    "    with open(FILENAME_CONFIG, \"r\") as file:\n",
    "        url_vinted = file.read()\n",
    "    print(\"URL récupérée :\", url_vinted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_vinted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accepter les cookies si nécessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cookies_button = driver.find_element(By.ID, ID_COOKIES_BUTTON)\n",
    "    cookies_button.click()\n",
    "except Exception as e:\n",
    "    # S'il n'y a pas la popup des cookies\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'utilisateur doit d'abord choisir les filtres par défaut manuellement sur l'interface du navigateur. \n",
    "\n",
    "Une fois cette étape accomplie, il doit exécuter la cellule suivante pour enregistrer les filtres de Vinted afin de les réutiliser lors de ses prochaines visites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILENAME_CONFIG, \"w\") as file:\n",
    "    file.write(driver.current_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions génériques de navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche maintenant à récupérer tous les URLS de tous les produits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_urls_page():\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    Extract all URLs of products for sale on the opened page.\n",
    "\n",
    "    Returns:\n",
    "    All product urls of the current opened page. This is a list of urls (strings).\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    items = soup.find_all(\"a\", class_=CLASS_ITEM_SALE)\n",
    "    urls = [item['href'] for item in items]\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parcourir toute les pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_to_next_page():\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    This function checks if a next page is available in a pagination system.\n",
    "    If a next page is available, it navigates to that page and returns True.\n",
    "    If no next page is available, it returns False without navigating.\n",
    "\n",
    "    Returns:\n",
    "    - True if a next page is available and the navigation is successful.\n",
    "    - False if no next page is available or if the navigation fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        next_button = driver.find_element(By.CLASS_NAME, CLASS_NEXT_PAGE)\n",
    "        next_button.click()\n",
    "        WebDriverWait(driver, 10).until(EC.staleness_of(next_button))\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url_already_visited(urls_to_check, old_urls):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    This function filters a list of new URLs, removing those that have already been processed based on URLs that have been previously visited.\n",
    "\n",
    "    Parameters:\n",
    "    - urls_to_check: A list of new URLs (strings) that need to be filtered based on whether they have been processed or not. The list is ordered by publication date.\n",
    "    - old_urls: A list of URLs (strings) that have already been processed and should be used for comparison. The list is ordered by publication date.\n",
    "\n",
    "    Returns:\n",
    "    - A boolean indicating whether any URLs were removed from the original list.\n",
    "    - A list containing only the URLs that are newer than all URLs from old_urls.\n",
    "\n",
    "    Example:\n",
    "    Consider the following example:\n",
    "    - urls_to_check = [\"a\", \"b\", \"c\"]\n",
    "    - old_urls = [\"b\", \"c\", \"e\", \"d\"]\n",
    "    The function will return True and [\"a\"], as all URLs are ordered by time, so \"e\" is older than \"c\". The function ensure that only the latest products are included.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    \n",
    "    for url in urls_to_check:\n",
    "        if url in old_urls:\n",
    "            return True, res\n",
    "        res.append(url)\n",
    "    return False, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigate_between_pages(urls_already_visited, sort_urls):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    This function facilitates navigation between pages, enabling the traversal of URLs while avoiding previously visited product URLs. The function iterates through pages until an already visited URL is encountered, ensuring efficient traversal of items.\n",
    "\n",
    "    Parameters:\n",
    "    - urls_already_visited: A list of URLs (strings) that have already been visited.\n",
    "    - sort_urls: A callback function that is called with all URLs not yet visited for each page. A list of URLs (strings) is provided for each new page.\n",
    "\n",
    "    Returns:\n",
    "    This function does not explicitly return a value. Instead, it efficiently navigates through URLs while considering those already visited, ensuring optimal processing and traversal.\n",
    "    \"\"\"\n",
    "    next_page = True\n",
    "    i = 0\n",
    "    while next_page and i<2:\n",
    "        i+=1\n",
    "        print(f\"Page n°{i}\")\n",
    "        \n",
    "        urls_items = extract_urls_page()\n",
    "        has_removed_url, urls_items_not_visited = remove_url_already_visited(urls_items, urls_already_visited)\n",
    "        sort_urls(urls_items_not_visited)\n",
    "\n",
    "        if has_removed_url:\n",
    "            next_page = False\n",
    "        else:\n",
    "            next_page = go_to_next_page()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trier produits en fonction des pays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons un dictionnaire qui va stocker les différentes URLs des produits triées par localisation de vente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_location = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous récupérons les données collectées lors des sessions précédentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(PATH_OUTPUT_LOCATION):\n",
    "    with open(PATH_OUTPUT_LOCATION, \"r\") as file:\n",
    "        urls_location = json.load(file)\n",
    "    print(\"Données des recherches antérieures chargées\")\n",
    "else:\n",
    "    print(\"Aucune recherche antérieure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons maintenant une fonction qui trie les nouvelles URLs des produits en fonction de leur localisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_urls_by_location(urls_items):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    This function sorts the URLs of products based on their location. It navigates to each URL, extracts the location information, and organizes the URLs in a global dictionary called urls_location, with the location as the key and a list of URLs belonging to that location.\n",
    "\n",
    "    Parameters:\n",
    "    - urls_items: A list of URLs (strings) representing the products to be sorted based on location.\n",
    "\n",
    "    Operation:\n",
    "    The function iterates through the URLs, visits each URL to extract location information, and categorizes the URLs based on their location in the global urls_location dictionary.\n",
    "\n",
    "    Note: The global variable urls_location is used to store the sorted URLs.\n",
    "    \"\"\"\n",
    "    global urls_location\n",
    "\n",
    "    url_product_list = driver.current_url\n",
    "\n",
    "    for url in urls_items:\n",
    "        driver.get(url)\n",
    "        time.sleep(0.5)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        div_location = soup.find(\"div\", {\"data-testid\": DATA_TESTID_LOCATION_PARENT})\n",
    "\n",
    "        if div_location:\n",
    "            location = div_location.find(\"div\", class_=CLASS_LOCATION_VALUE)\n",
    "            if location:\n",
    "                if location.text in urls_location:\n",
    "                    urls_location[location.text].append(url)\n",
    "                else:\n",
    "                    urls_location[location.text] = [url]\n",
    "            else:\n",
    "                print(\"Localisation non mentionnée\")\n",
    "        else:\n",
    "            print(\"Description localisation manquante\")\n",
    "            print(driver.page_source)\n",
    "\n",
    "        # driver.back()  \n",
    "    driver.get(url_product_list) # Revenir en arrière pour continuer la recherche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupère toutes les URLs déjà visitées à partir du dictionnaire des URLs des produits par pays, puis les fusionne dans une liste unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_already_visited = []\n",
    "for location in urls_location.values():\n",
    "    urls_already_visited.extend(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous lançons la navigation entre les pages avec les URLs des produits déjà visités par pays, intégrant chaque nouveau produit dans le dictionnaire des produits par pays correspondant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navigate_between_pages(urls_already_visited, sort_urls_by_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarde des résultats dans le fichier de sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DIRECTORY_OUTPUT):\n",
    "    os.makedirs(DIRECTORY_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_OUTPUT_LOCATION, \"w\") as file:\n",
    "    json.dump(urls_location, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produits pour un pays donné\n",
    "Filtrer les produits en fonction d'une localisation précise.\n",
    "Nécessite l'exécution des cellules de la section précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_urls_by_location(urls_location, location):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    This function filters URLs of products based on a specified location. It takes two parameters: the `urls_location` dictionary, which contains URLs categorized by their respective locations, and the `location` string representing the target location for filtering. The function iterates through the `urls_location` dictionary, creating a new dictionary called `url_filtered` that includes only the URLs associated with the specified location.\n",
    "\n",
    "    Parameters:\n",
    "    - urls_location: A dictionary containing URLs sorted by location, where keys represent location names, and values are lists of URLs associated with those locations.\n",
    "    - location: The target location for filtering the URLs.\n",
    "\n",
    "    Returns:\n",
    "    A new dictionary (`url_filtered`) containing URLs sorted by location, where the keys are location names containing the specified location, and the values are lists of URLs associated with those locations.\n",
    "    \"\"\"\n",
    "    url_filtered = {}\n",
    "    for key, value in urls_location.items():\n",
    "        if location in key:\n",
    "            url_filtered[key] = value\n",
    "    return url_filtered\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_urls_by_location(urls_location, KEY_WORD_LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marques les plus répandues par pays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fermer le navigateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
